---
layout: post
title: "Spatial Intro 03: Data About Data -- Intro to Metadata File Formats and Structure"
date:   2015-10-27
authors: [Leah A. Wasser, Megan A. Jones]
contributors: [ ]
dateCreated: 2015-10-27
lastModified: `r format(Sys.time(), "%Y-%m-%d")`
packagesLibraries: [raster, rgdal, eml, devtools]
category: [self-paced-tutorial] 
tags: [R, spatial-data-gis, metadata]
mainTag: spatial-data-management-series
workshopSeries: [spatial-data-management-series]
description: "This tutorial covers what metadata are and why we need to work 
with metadata. It discusses metadata in the context of spatio-temporal data. It 
covers the three most common metadata formats for ecological data: text file 
format, web page format and Ecological Metadata Language (EML)."
code1: 03-metadata-formats-and-files.R
image:
  feature: NEONCarpentryHeader_2.png
  credit: A collaboration between the National Ecological Observatory Network (NEON) and Data Carpentry
  creditlink: 
permalink: /R/metadata-file-formats-structures
comments: true
---

{% include _toc.html %}

This tutorial covers what metadata are and why we need to work 
with metadata. It discusses metadata in the context of spatio-temporal data. It 
covers the three most common metadata formats for ecological data: text file 
format, web page format and Ecological Metadata Language (EML).

**R Skill Level:** None. This tutorial is in a series with data skills
intensive tutorials in the `R` programming language, however, the conceptual
topics presented here relate to all programming languages!

<div id="objectives" markdown="1">

# Goals / Objectives

After completing this activity, you will:

* Understand that metadata come in many formats and must be maintained with the
data. 
* Understand that there is necessary metadata associated with and/or embedded in
the data.
* Understand that collecting data requires and includes collecting the metadata.
* Be able to create metadata files for different data types. 


### Install R Packages

**OPTIONAL** This tutorial uses these `R` packages in examples. However, the
teaching of these skills are taught in other tutorials (linked to in the 
tutorial).

* **raster:** `install.packages("raster")`
* **rgdal:** `install.packages("rgdal")`
* **devtools** `install.packages("devtools")` 
* **eml** `install_github("ropensci/EML", build=FALSE, dependencies=c("DEPENDS", "IMPORTS"))`

* [More on Packages in R - Adapted from Software Carpentry.]({{site.baseurl}}R/Packages-In-R/)

****

{% include/_greyBox-wd-rscript.html %}

****

### Additional Resources

* Information on the 
<a href="http://cran.r-project.org/web/packages/raster/raster.pdf" target="_blank"> `raster` R package</a> 

</div>

```{r elevation-map, include=TRUE, results="hide", echo=FALSE}
#render DSM for lesson content background
DSM_HARV <- raster("NEON-DS-Airborne-Remote-Sensing/HARV/DSM/HARV_dsmCrop.tif")

# code output here - DEM rendered on the screen
plot(DSM_HARV,
      main="A Dataset You Are Given\n What metric does it represent?\nHow Was It Processed??")

```


<div id="challenge" markdown="1">
## Challenge: What Do I Know About My Data?

The figure above was create from a hypothetical data set that you are given 
called: `HARV_dsmCrop.tif`. 

What other information would you like to know about the data used to create the 
above map before you would feel comfortable using this data to address a 
research question? 

How does thinking about this plot and what you'd like to know about it influence
how you think about sharing data with a colleague? 

</div>

```{r challenge-know-the-data, echo=FALSE}

# Everything! We have no idea what this raster represents (what metric),
# what the units are, what the scale represents, when it was collected, etc. 
# When we create data it needs to be document sufficiently (and efficiently) 
# for sharing with others.

```

## Why Do We Need Metadata?

Looking at the map above, we are missing information needed to begin working 
with the data effectively, including:

**Spatial Information**

* **Spatial Extent:** What area does this dataset cover? 
* **Coordinate reference system:** What spatial projection / coordinate reference
system are used to store the data? Will it line up with other data? 
* **Resolution:** The data appears to be in **raster** format. This means it is
composed of pixels. What area on the ground does each pixel cover - i.e. What is 
its spatial resolution?

**Data Collection / Processing Methods**

* **When was the data collected?** Is it recent or historical?
* **How was this data generated?** Is this an output from a model, is it an image
from a remote sensing instrument such as a satellite (e.g. Landsat) or collected
from an airplane? How were the data collected?
* **Units:** We can see a scale bar of values to the right of the data, however, 
what metric and in what units does this represent? Temperature? Elevation? Precipitation?
* **How were the data processed?**

**Contact Information**

* **Who created this data?** 
* **Who do we contact:** We might need permission to use it, have questions
about the data, or need more information to give correct attribution.

When we are given a dataset, or when we download it online, we do not know
anything about it without proper documentation. This documentation is called 
**metadata** - data about the data.

## What are Metadata?
Metadata are structured information that describes a dataset. Metadata include 
a suite of information about the data including:

* Contact information,
* Spatial Attributes including: extent, coordinate reference system, resolution,
* Data collection & processing methods,
* and much more.

Without sufficient documentation, it is difficult for us to work with external 
data - data that we did not collect ourselves.

### Why Are Metadata Needed?

We have discussed that metadata are important for knowing about our data, either
data we collect ourselves or external data we use. 

## Metadata Formats

Metadata comes in different formats. We will discuss three of those in this 
tutorial:

* **Structured Embedded Metadata:** Some file formats supported embedded 
metadata which you can access from a tool like `R` or `Python` directly from the 
imported data (e.g. **GeoTIFF** and **HDF5**). This data is contained in the same 
file (or file set as for shapefiles) as the data. 
* **Structured Metadata Files:** Structured metadata files, such as the 
Ecological Metadata Language (**EML**), are stored in a machine readable format 
which means they can be accessed using a tool like `R` or `Python`. These files
must be shared with and accompany the separate data files. There are 
different file formats and standards so it's important to understand that 
standards will vary.
* **Unstructured Metadata Files:** This broad group include text files, 
web pages and other documentation that does not follow a particular standard or 
format, but documents key attributes required to work with the data. 

Structured metadata formats are ideal if you can find them because they are most 
often:

* In a standard, documented format that others use.
* Are machine readable which means you can use them in scripts and algorithms.

<i class="fa fa-star"></i> **Data Note:** When you find metadata for a dataset 
that you are working with, **DOWNLOAD AND SAVE IT** immediately to the directory 
on your computer where you saved the data. It is also a good idea to document
the URL where you found the metadata and the data in a "readme" text file that 
is also stored with the data!
{: .notice}


## Embedded Metadata - GeoTIFF

If we want to automate workflows, it's ideal for key metadata required to 
process our data to be embedded directly in our data files. The **GeoTIFF**
(`fileName.tif`) is one common spatio-temporal format that can store
**metadata** directly in the `.tif` file itself.

### What is a GeoTIFF??

A **GeoTIFF** file stores metadata or attributes about the file as embedded
`tif tags`. A GeoTIFF is a standard `.tif` image format with additional spatial
(georeferencing) information embedded in the file as tags. These tags can 
include the following raster metadata:

1. A Coordinate Reference System (CRS)
2. Spatial Extent
3. Values for when no data is provided (NoData Value)
4. The resolution of the data

<i class="fa fa-star"></i> **Data Note:**  Your camera uses embedded tags to store
information about pictures that you take including the camera make and model, 
and the time the image was taken!
{: .notice }

More about the  `.tif` format:

* <a href="https://en.wikipedia.org/wiki/GeoTIFF" target="_blank"> GeoTIFF on Wikipedia</a>
* <a href="https://trac.osgeo.org/geotiff/" target="_blank"> OSGEO TIFF documentation</a>

The `raster` package in `R` allows us to directly access `.tif tags`
programmatically. We can quickly view the spatial **extent**, 
**coordinate reference system** and **resolution** of the data. 

The code below is provided as an example of how we can access this information
in `R`. We teach how to access this information and why this is particularly 
important spatial metadata in a step-by-step progression in the 
[*Intro to Raster Data in R* tutorial](http://www.neondataskills.org/R/Introduction-to-Raster-Data-In-R). 

```{r load-libraries }
# load libraries
library(raster)
library(rgdal)

# set working directory to ensure R can find the file we wish to import
# setwd("working-dir-path-here")

# read in a GeoTIFF raster file (.tif) using the raster() function
DSM_HARV <- raster("NEON-DS-Airborne-Remote-Sensing/HARV/DSM/HARV_dsmCrop.tif")

# view Coordinate Reference System (note, this often contains horizontal units!)
crs(DSM_HARV)

# view spatial extent
extent(DSM_HARV)

# view spatial resolution
res(DSM_HARV)

# print object name to return metadata & attribute data about object
DSM_HARV
```


We can use embedded metadata to programmatically perform processing tasks 
on our data including reprojections, cropping and more.

We will work with embedded metadata in both the 
[*Introduction to Working With Vector Data in R*]( http://www.neondataskills.org/tutorial-series/vector-data-series/) 
and 
[*Introduction to Working With Raster Data in R*]( http://www.neondataskills.org/tutorial-series/raster-data-series/) 
series!

## Embedded Metadata - Hierarchical Data Formats (HDF5)

HDF5 is another file type that supports embedded metadata format. Check out the 
[NEON Data Skills HDF5 tutorials](http://www.neondataskills.org/tutorial-series/intro-hdf5-r-series/)  to learn more about how HDF5 stores metadata.

## Structured Metadata - EML

The Ecological Metadata Language (EML) is a data specification developed
specifically to document ecological data. An EML file is created using a **XML-
based format**.

This means that content is embedded within hierarchical tags. For example
the title of a dataset might be embedded in a `<title>` tag as follows:

	 <title>Fisher Meteorological Station at Harvard Forest since 2001</title>

Similarly, the creator of a dataset is also be found in a hierarchical tag
structure.

    <creator>
      <individualName>
        <givenName>Emery</givenName>
        <surName>Boose</surName>
      </individualName>
    </creator>
    


## EML Terminology

Let's first discuss some basic **EML** terminology. In the 
context of EML, a file documents a **dataset**. This dataset may consist of one
or more files that are documented in the EML document. In the case of our 
tabular meteorology data, the structure of our EML file includes:

1. The **dataset**: A dataset may contain one or more data tables associated 
with it that may contain different types of related information. This 
Harvard meteorological dataset contains data tables with the measurements 
collected at the tower. 
2. The **data tables**: Data tables refer to the actual data that make up the
dataset. For the Harvard dataset, each data table contains a suite of 
meteorological metrics including precipitation and temperature (and associated
quality flags) that are aggregated at a particular time interval (e.g. one data
table contains monthly average data, another contains 15 minute averaged data,
etc)


## Work With EML in R 

The `EML` package for `R` is designed to open, read and create EML formatted 
metadata. In this tutorial, we will overview demonstrate how we can use EML
structured metadata in an automated workflow. 

NOTE: To save time, we will not explicitly teach the `EML` package given it is
still being developed. But we will provide an example of how you can access 
EML metadata programmatically using the `EML` package.

To begin, we will load the `EML` package directly from 
<a href="https://github.com/ropensci" target="_blank">ropensci's Git repository </a>.

```{r install-EML-package, results="hide", warning=FALSE }
# install R EML tools
library("devtools")
install_github("ropensci/EML", build=FALSE, dependencies=c("DEPENDS", "IMPORTS"))

# load ROpenSci EML package
library("EML")

# load ggmap for mapping
library(ggmap)


# data location
# http://harvardforest.fas.harvard.edu:8080/exist/apps/datasets/showData.html?id=hf001
# table 4 http://harvardforest.fas.harvard.edu/data/p00/hf001/hf001-04-monthly-m.csv
```

Next, we will read in the Harvard Forest LTER `EML` file directly from the 
online URL using the `read_eml()` function. This file describes multiple data
products that are available for downloaded on the
<a href="http://harvardforest.fas.harvard.edu:8080/exist/apps/datasets/showData.html?id=hf001" target="_blank"> Harvard Forest Data Archive Page for Fisher Meteorological Station.</a>

Note that because this EML file is large, it takes quite a few seconds for the file to 
load.


```{r read-eml }
# import EML from Harvard Forest Met Data
eml_HARV <- read_eml("http://harvardforest.fas.harvard.edu/data/eml/hf001.xml")

# view size of object
object.size(eml_HARV)

# view the object class
class(eml_HARV)
```

The `read_eml()` function creates an `EML` class object. This object can be
accessed using `slots` in `R` (`@`) rather than a typical subset `[ ]` approach.

## Explore Metadata Attributes

We can begin to explore the contents of our EML file and associated data that it
describes. Let's start at the **dataset** level. We can use `eml_get` to view 
the contact information for the dataset, the keywords and it's associated
temporal and spatial (if relevant) coverage.

```{r view-eml-content }
# view the contact name listed in the file
# this works well!
#eml_get(eml_HARV,"contact")

# grab all keywords in the file
#eml_get(eml_HARV,"keywords")

# figure out the extent & temporal coverage of the data
#eml_get(eml_HARV,"coverage")

```


## Identify & Map Data Location

Looking at the coverage for our data, there is only one unique x and y value. 
This suggests that our data were collected at one point (x, y) location. We 
know this is data from a tower so a point location makes sense. Let's grab the 
x and y coordinates and create a quick context map. We will use `ggmap` to create our map.

<i class="fa fa-star"></i> **Data Note:**  If this were a rectangular extent 
(e.g. from a raster, line or polygon object) we'd want the bounding box, not 
just a point within the extent. We need the extent to properly geolocate and 
process the data.
{: .notice}


```{r map-location, warning=FALSE, message=FALSE}
# grab x coordinate
#XCoord <- eml_HARV@dataset@coverage@geographicCoverage@boundingCoordinates@westBoundingCoordinate
# grab y coordinate
#YCoord <- eml_HARV@dataset@coverage@geographicCoverage@boundingCoordinates@northBoundingCoordinate


# map <- get_map(location='Harvard', maptype = "terrain")
#map <- get_map(location='massachusetts', maptype = "toner", zoom =8)

#ggmap(map, extent=TRUE) +
#  geom_point(aes(x=XCoord,y=YCoord), 
#             color="darkred", size=6, pch=18)

```

The above example demonstrates how we can extract information from an **EML**
document and use it programmatically in `R`! This is just the beginning of what 
we can do!

* Learn More:<a href="https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/ggmap/ggmapCheatsheet.pdf" target="_blank"> A nice cheatsheet for GGMAP created by NCEAS</a>

## Unstructured Metadata - Web pages & Text Files

Some metadata are stored in a less or non-structured format such as a web page
or a text file. 

Let's visit the 
<a href="http://harvardforest.fas.harvard.edu:8080/exist/apps/datasets/showData.html?id=hf001" target="_blank"> Harvard Forest Fisher Tower webpage</a>
to explore some unstructured metadata. 

Visiting this page, we see a list of data files available for Harvard Forest 
that can be downloaded directly. Hovering over the files with our mouse, we can 
see that these are .csv tabular text files. 

Scroll down to the **Overview** section. Here we start to see information that
can be considered metadata about the data available for download.


<div id="challenge" markdown="1">
## Challenge - Explore Unstructured Metadata

Explore the metadata stored on the Harvard Forest LTER web page. Answer the 
following questions. 

1. What is the time span of the data available for this site? 
2. You have some questions about these data. Who is the lead investigator / who 
do you contact for more information? And how do you contact them? 
3. Where is this field site located? How is the site location information stored
in the metadata? Is there any information that may be useful to you viewing the 
location? (HINT: what if you were not familiar with Harvard as a site or are
from another country, etc?)
4. Field Site Information: What is the elevation for the site? What is the
dominant vegetation cover for the site? HINT: Is dominant vegetation easy to 
find in the metadata?
5. How is snow dealt with in the precipitation data?
6. Are there some metadata attributes that might be useful to access in a script
in `R` or `Python` rather than viewed on a web page?

HINT: Can you answer all of the questions above from the information provided
on this website? Is there information that you might prefer to find on that page?
</div>

```{r challenge-code-metadata, echo=FALSE}
# Metadata Notes from hf001_10-15-m_Metadata.txt
# 1. 2001-2015
# 2. Emery Boos - located at the top of the document, email is available
# 3. a lat long is available in the metadata at the top, we see the location # described as Prospect Hill Tract (Harvard Forest). 
# 4. 342 m elevation, the veg type is not clear in the metadata
# 5. Found in the methods: Delayed melting of snow and ice (caused by problems with rain gage heater or heavy precipitation) is noted in log - daily values are corrected if necessary but 15-minute values are not. The gage may underestimate actual precipitation under windy or cold conditions.
# 6. this could be a discussion. things like units, time zone, etc are all useful
# if accessed programmatically

```

NOTE: This data and metadata are used in the 
[*Introduction to Working With Time Series Data in Text Formats in R* series](http://www.neondataskills.org/tutorial-series/tabular-time-series/).


## Data Management - Metadata

Metadata are particularly important when we are working with data that we did 
not collect ourselves. When you download, or gain access to data from a 
colleague, or other data provider, be sure to first find and review the 
metadata. Then, if the data is in a seperate file (e.g., structured or
unstructured metadata) make sure you save the metadata in a directory that is 
closely associated with wherever you save the data itself! 


## Create Metadata For Your Data

When you are creating data that you want to share with others, it is critical
to create your own metadata. While this is beyond the scope of this tutorial,
There are many resources available to support metadata documentation including:

* <a href="https://knb.ecoinformatics.org/#tools/morpho" target="_blank"> **Morpho**</a>:
an open-source program that can be used to enter metadataa to be stored in a 
file that conforms to the Ecological Metadata Language (EML) specifications. 

<div id="challenge" markdown="1">
## Challenge: Find & Explore Metadata

Refer back to the list of possible data sources at the end of 
[*Answer a Spatio-temporal Research Question with Data: Where to Start?*]({{ site.baseurl}}/R/spatio-temporal-research-questions#resources-for-locating-spatial-and-ecological-data).
Choose a site that is relevant to your interests and then find a dataset. For
this data set find the metadata and answer the following questions: 

1. What format are the metadata in? 
2. What metric is collected? Does it have units? If so, what?
3. Who collected the data? Using what type of instruments? 

Note: no challenge answer code for this challenge as each data source and 
associated metadata will be different. 

</div>

## ATBD vs Metadata

An Algorithm Theoretical Basis Document (ATBD) is a document which describes the 
collection and processing methods associated with a data product. While these
documents are beyond the scope of this tutorial, it is important to note that
often important information about your data may be documented in documents
such as ATBDs. 

* <a href="http://data.neoninc.org/documents" target="_blank">NEON</a> 
provides ATBDs for all of it's data products.
